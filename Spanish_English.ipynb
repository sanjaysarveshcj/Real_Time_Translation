{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4RDM4CdlIOw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9RHUNWSlIOx"
   },
   "outputs": [],
   "source": [
    "class NeuralMachineTranslation:\n",
    "    def __init__(self, max_sequence_length=10):\n",
    "        \"\"\"\n",
    "        Initialize Neural Machine Translation Model\n",
    "\n",
    "        Args:\n",
    "            max_sequence_length (int): Maximum length of input/output sequences\n",
    "        \"\"\"\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.input_tokenizer = None\n",
    "        self.output_tokenizer = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, input_texts, output_texts):\n",
    "        \"\"\"\n",
    "        Prepare input and output texts for training\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): List of input language sentences\n",
    "            output_texts (list): List of output language sentences\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tokenized and padded input and output sequences\n",
    "        \"\"\"\n",
    "        # Tokenize input texts\n",
    "        self.input_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.input_tokenizer.fit_on_texts(input_texts)\n",
    "        input_sequences = self.input_tokenizer.texts_to_sequences(input_texts)\n",
    "        encoder_input_data = pad_sequences(input_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Tokenize output texts\n",
    "        self.output_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.output_tokenizer.fit_on_texts(output_texts)\n",
    "        output_sequences = self.output_tokenizer.texts_to_sequences(output_texts)\n",
    "        decoder_input_data = pad_sequences(output_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # One-hot encode output sequences\n",
    "        # Shift the target data by one time step\n",
    "        decoder_target_data = np.zeros((len(output_texts), self.max_sequence_length,\n",
    "                                        len(self.output_tokenizer.word_index) + 1), dtype='float32')\n",
    "\n",
    "        for i, sequence in enumerate(decoder_input_data):\n",
    "            for t, word_index in enumerate(sequence):\n",
    "                if word_index > 0 and t > 0:\n",
    "                    decoder_target_data[i, t-1, word_index] = 1.0\n",
    "\n",
    "        # Get vocabulary sizes\n",
    "        input_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
    "        output_vocab_size = len(self.output_tokenizer.word_index) + 1\n",
    "\n",
    "        return (encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "                input_vocab_size, output_vocab_size)\n",
    "\n",
    "    def build_model(self, input_vocab_size, output_vocab_size):\n",
    "        \"\"\"\n",
    "        Build the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_vocab_size (int): Size of input language vocabulary\n",
    "            output_vocab_size (int): Size of output language vocabulary\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        encoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        encoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
    "        encoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        # Decoder\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        decoder_embedding = tf.keras.layers.Embedding(\n",
    "            output_vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
    "        decoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(\n",
    "            decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "        # Dense output layer\n",
    "        decoder_dense = tf.keras.layers.Dense(\n",
    "            output_vocab_size, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        # Compile the model\n",
    "        model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, input_texts, output_texts, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): Training input language sentences\n",
    "            output_texts (list): Training output language sentences\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "        \"\"\"\n",
    "        # Prepare data\n",
    "        (encoder_input_data, decoder_input_data,\n",
    "         decoder_target_data, input_vocab_size,\n",
    "         output_vocab_size) = self.prepare_data(input_texts, output_texts)\n",
    "\n",
    "        # Build model\n",
    "        self.build_model(input_vocab_size, output_vocab_size)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            [encoder_input_data, decoder_input_data],\n",
    "            decoder_target_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the entire model to a specified filepath\n",
    "        \"\"\"\n",
    "        self.model.save(filepath, save_format='h5')\n",
    "\n",
    "    def translate(self, input_sentence):\n",
    "        \"\"\"\n",
    "        Translate a single sentence\n",
    "\n",
    "        Args:\n",
    "            input_sentence (str): Sentence to translate\n",
    "\n",
    "        Returns:\n",
    "            str: Translated sentence\n",
    "        \"\"\"\n",
    "        if not self.model or not self.input_tokenizer or not self.output_tokenizer:\n",
    "            raise ValueError(\"Model must be trained before translation\")\n",
    "\n",
    "        # Tokenize and pad input sentence\n",
    "        input_seq = self.input_tokenizer.texts_to_sequences([input_sentence])\n",
    "        input_padded = pad_sequences(input_seq, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Prepare decoder input\n",
    "        decoder_input = np.zeros((1, self.max_sequence_length))\n",
    "        decoder_input[0, 0] = self.output_tokenizer.word_index.get('<start>', 1)  # Start token\n",
    "\n",
    "        # Translation process\n",
    "        translated_words = []\n",
    "        for i in range(self.max_sequence_length):\n",
    "            # Predict next word\n",
    "            output = self.model.predict([input_padded, decoder_input])\n",
    "\n",
    "            # Get the index of the word with the highest probability\n",
    "            predicted_word_index = np.argmax(output[0, i, :])\n",
    "\n",
    "            # Convert index to word\n",
    "            predicted_word = self.output_tokenizer.index_word.get(predicted_word_index, '')\n",
    "\n",
    "            # Stop if no word is predicted or we've reached max length\n",
    "            if not predicted_word or predicted_word == '<end>':\n",
    "                break\n",
    "\n",
    "            translated_words.append(predicted_word)\n",
    "\n",
    "            # Update decoder input\n",
    "            decoder_input[0, i+1] = predicted_word_index\n",
    "\n",
    "        return ' '.join(translated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BNANiZ62lIOy"
   },
   "outputs": [],
   "source": [
    "def read_texts_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            # Strip whitespace and remove empty lines\n",
    "            texts = ['<start> ' + line.strip() + ' <end>' for line in file if line.strip()]\n",
    "        return texts\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXvtydmDlIOy",
    "outputId": "483b0f20-d0fe-4be4-9eee-fb10597e2587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - accuracy: 0.2019 - loss: 5.5134 - val_accuracy: 0.2245 - val_loss: 4.4255\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.2306 - loss: 4.2235 - val_accuracy: 0.2309 - val_loss: 4.3122\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.2343 - loss: 4.0986 - val_accuracy: 0.2344 - val_loss: 4.2411\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.2365 - loss: 4.0185 - val_accuracy: 0.2378 - val_loss: 4.1776\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.2415 - loss: 3.9255 - val_accuracy: 0.2404 - val_loss: 4.1152\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.2471 - loss: 3.8302 - val_accuracy: 0.2378 - val_loss: 4.0700\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.2523 - loss: 3.7318 - val_accuracy: 0.2401 - val_loss: 4.0393\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.2577 - loss: 3.6670 - val_accuracy: 0.2510 - val_loss: 3.9942\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.2719 - loss: 3.5577 - val_accuracy: 0.2554 - val_loss: 3.9539\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.2829 - loss: 3.4509 - val_accuracy: 0.2630 - val_loss: 3.9364\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.2963 - loss: 3.3499 - val_accuracy: 0.2700 - val_loss: 3.8905\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.3073 - loss: 3.2663 - val_accuracy: 0.2732 - val_loss: 3.8722\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.3216 - loss: 3.1541 - val_accuracy: 0.2732 - val_loss: 3.8270\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3286 - loss: 3.0672 - val_accuracy: 0.2780 - val_loss: 3.8076\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.3412 - loss: 2.9552 - val_accuracy: 0.2805 - val_loss: 3.7960\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.3525 - loss: 2.8712 - val_accuracy: 0.2858 - val_loss: 3.8054\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.3617 - loss: 2.7936 - val_accuracy: 0.2837 - val_loss: 3.7936\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3747 - loss: 2.7020 - val_accuracy: 0.2895 - val_loss: 3.7642\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.3833 - loss: 2.6269 - val_accuracy: 0.2901 - val_loss: 3.7660\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.3947 - loss: 2.5438 - val_accuracy: 0.2903 - val_loss: 3.7683\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.4009 - loss: 2.4638 - val_accuracy: 0.2909 - val_loss: 3.7808\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.4113 - loss: 2.4054 - val_accuracy: 0.2910 - val_loss: 3.7807\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.4202 - loss: 2.3240 - val_accuracy: 0.2958 - val_loss: 3.7838\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.4276 - loss: 2.2759 - val_accuracy: 0.2942 - val_loss: 3.8224\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.4383 - loss: 2.1996 - val_accuracy: 0.2942 - val_loss: 3.8136\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.4508 - loss: 2.1154 - val_accuracy: 0.2946 - val_loss: 3.8235\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.4607 - loss: 2.0483 - val_accuracy: 0.2986 - val_loss: 3.8456\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.4694 - loss: 1.9977 - val_accuracy: 0.2995 - val_loss: 3.8355\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.4790 - loss: 1.9383 - val_accuracy: 0.3004 - val_loss: 3.8438\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.4841 - loss: 1.8923 - val_accuracy: 0.2998 - val_loss: 3.8780\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.4953 - loss: 1.8128 - val_accuracy: 0.2992 - val_loss: 3.8777\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.5068 - loss: 1.7563 - val_accuracy: 0.3012 - val_loss: 3.8772\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.5139 - loss: 1.7055 - val_accuracy: 0.3022 - val_loss: 3.8934\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.5228 - loss: 1.6569 - val_accuracy: 0.3021 - val_loss: 3.9340\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.5339 - loss: 1.6045 - val_accuracy: 0.3012 - val_loss: 3.9116\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.5412 - loss: 1.5434 - val_accuracy: 0.3029 - val_loss: 3.9561\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.5515 - loss: 1.4956 - val_accuracy: 0.3051 - val_loss: 3.9408\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.5612 - loss: 1.4340 - val_accuracy: 0.3024 - val_loss: 3.9586\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.5662 - loss: 1.4090 - val_accuracy: 0.3024 - val_loss: 3.9681\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.5735 - loss: 1.3628 - val_accuracy: 0.3068 - val_loss: 3.9657\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.5801 - loss: 1.3206 - val_accuracy: 0.3060 - val_loss: 4.0014\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.5902 - loss: 1.2695 - val_accuracy: 0.3068 - val_loss: 4.0224\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.5953 - loss: 1.2437 - val_accuracy: 0.3051 - val_loss: 4.0177\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.6058 - loss: 1.1916 - val_accuracy: 0.3049 - val_loss: 4.0318\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.6102 - loss: 1.1654 - val_accuracy: 0.3081 - val_loss: 4.0649\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.6198 - loss: 1.1117 - val_accuracy: 0.3096 - val_loss: 4.0621\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.6236 - loss: 1.0916 - val_accuracy: 0.3086 - val_loss: 4.0875\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.6333 - loss: 1.0479 - val_accuracy: 0.3122 - val_loss: 4.0608\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6403 - loss: 1.0074 - val_accuracy: 0.3082 - val_loss: 4.0931\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.6490 - loss: 0.9752 - val_accuracy: 0.3074 - val_loss: 4.1016\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6526 - loss: 0.9398 - val_accuracy: 0.3108 - val_loss: 4.1092\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6561 - loss: 0.9258 - val_accuracy: 0.3086 - val_loss: 4.1470\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6641 - loss: 0.8902 - val_accuracy: 0.3092 - val_loss: 4.1445\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6724 - loss: 0.8448 - val_accuracy: 0.3117 - val_loss: 4.1617\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6774 - loss: 0.8272 - val_accuracy: 0.3091 - val_loss: 4.1662\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.6792 - loss: 0.8157 - val_accuracy: 0.3132 - val_loss: 4.1679\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.6872 - loss: 0.7725 - val_accuracy: 0.3107 - val_loss: 4.1850\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6901 - loss: 0.7620 - val_accuracy: 0.3119 - val_loss: 4.1809\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6969 - loss: 0.7303 - val_accuracy: 0.3107 - val_loss: 4.2019\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7023 - loss: 0.7017 - val_accuracy: 0.3112 - val_loss: 4.2218\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7087 - loss: 0.6687 - val_accuracy: 0.3118 - val_loss: 4.2382\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7102 - loss: 0.6659 - val_accuracy: 0.3124 - val_loss: 4.2385\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7173 - loss: 0.6278 - val_accuracy: 0.3125 - val_loss: 4.2550\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7206 - loss: 0.6030 - val_accuracy: 0.3102 - val_loss: 4.2718\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7246 - loss: 0.5969 - val_accuracy: 0.3116 - val_loss: 4.2776\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7298 - loss: 0.5577 - val_accuracy: 0.3103 - val_loss: 4.2855\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7341 - loss: 0.5452 - val_accuracy: 0.3136 - val_loss: 4.2921\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.7378 - loss: 0.5181 - val_accuracy: 0.3122 - val_loss: 4.3008\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7408 - loss: 0.5082 - val_accuracy: 0.3112 - val_loss: 4.3203\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7435 - loss: 0.4883 - val_accuracy: 0.3122 - val_loss: 4.3301\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7457 - loss: 0.4777 - val_accuracy: 0.3131 - val_loss: 4.3496\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7485 - loss: 0.4576 - val_accuracy: 0.3123 - val_loss: 4.3492\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7535 - loss: 0.4387 - val_accuracy: 0.3120 - val_loss: 4.3512\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7552 - loss: 0.4269 - val_accuracy: 0.3115 - val_loss: 4.3555\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7582 - loss: 0.4083 - val_accuracy: 0.3112 - val_loss: 4.3833\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7582 - loss: 0.4004 - val_accuracy: 0.3140 - val_loss: 4.4012\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7614 - loss: 0.3827 - val_accuracy: 0.3121 - val_loss: 4.4163\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7624 - loss: 0.3684 - val_accuracy: 0.3151 - val_loss: 4.4375\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7642 - loss: 0.3617 - val_accuracy: 0.3132 - val_loss: 4.4336\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7681 - loss: 0.3453 - val_accuracy: 0.3137 - val_loss: 4.4302\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7691 - loss: 0.3319 - val_accuracy: 0.3147 - val_loss: 4.4430\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7705 - loss: 0.3165 - val_accuracy: 0.3133 - val_loss: 4.4715\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7727 - loss: 0.3133 - val_accuracy: 0.3128 - val_loss: 4.4736\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7740 - loss: 0.2995 - val_accuracy: 0.3120 - val_loss: 4.4994\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.7743 - loss: 0.2891 - val_accuracy: 0.3108 - val_loss: 4.5011\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7763 - loss: 0.2806 - val_accuracy: 0.3111 - val_loss: 4.5033\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.7786 - loss: 0.2751 - val_accuracy: 0.3120 - val_loss: 4.5148\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.7789 - loss: 0.2650 - val_accuracy: 0.3150 - val_loss: 4.5318\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7813 - loss: 0.2534 - val_accuracy: 0.3126 - val_loss: 4.5156\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7811 - loss: 0.2415 - val_accuracy: 0.3126 - val_loss: 4.5463\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7819 - loss: 0.2354 - val_accuracy: 0.3143 - val_loss: 4.5620\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7832 - loss: 0.2308 - val_accuracy: 0.3147 - val_loss: 4.5657\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7831 - loss: 0.2222 - val_accuracy: 0.3114 - val_loss: 4.5724\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7848 - loss: 0.2159 - val_accuracy: 0.3107 - val_loss: 4.5748\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7850 - loss: 0.2056 - val_accuracy: 0.3110 - val_loss: 4.5850\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7869 - loss: 0.1975 - val_accuracy: 0.3125 - val_loss: 4.6002\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7858 - loss: 0.1884 - val_accuracy: 0.3153 - val_loss: 4.5985\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7861 - loss: 0.1823 - val_accuracy: 0.3112 - val_loss: 4.6318\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7862 - loss: 0.1827 - val_accuracy: 0.3107 - val_loss: 4.6234\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7880 - loss: 0.1761 - val_accuracy: 0.3128 - val_loss: 4.6132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Input: ¡Intentemos algo!\n",
      "Translation: Arrive\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    model_save_path = 'sp_en_model.h5'\n",
    "\n",
    "\n",
    "    input_texts = read_texts_from_file('datasets/spanish')\n",
    "    output_texts = read_texts_from_file('datasets/eng_sp.en')\n",
    "\n",
    "    input_texts = input_texts[:10000]\n",
    "    output_texts = output_texts[:10000]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    nmt_model = NeuralMachineTranslation(max_sequence_length=5)\n",
    "\n",
    "    # Train the model\n",
    "    nmt_model.train(input_texts, output_texts, epochs=100)\n",
    "    nmt_model.save(model_save_path)\n",
    "\n",
    "    with open(\"sp_en_input_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.input_tokenizer, f)\n",
    "\n",
    "    with open(\"sp_en_output_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.output_tokenizer, f)\n",
    "\n",
    "\n",
    "\n",
    "    # Translate the first sentence\n",
    "    if input_texts:\n",
    "        input_sentence = input_texts[0].replace('<start>', '').replace('<end>', '').strip()\n",
    "        translation = nmt_model.translate(input_sentence)\n",
    "        print(f\"Input: {input_sentence}\")\n",
    "        print(f\"Translation: {translation}\")\n",
    "    else:\n",
    "        print(\"No input texts available for translation.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
