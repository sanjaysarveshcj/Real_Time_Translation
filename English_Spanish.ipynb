{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWNTL3zociVv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVJfeCs0ciVw"
   },
   "outputs": [],
   "source": [
    "class NeuralMachineTranslation:\n",
    "    def __init__(self, max_sequence_length=10):\n",
    "        \"\"\"\n",
    "        Initialize Neural Machine Translation Model\n",
    "\n",
    "        Args:\n",
    "            max_sequence_length (int): Maximum length of input/output sequences\n",
    "        \"\"\"\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.input_tokenizer = None\n",
    "        self.output_tokenizer = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, input_texts, output_texts):\n",
    "        \"\"\"\n",
    "        Prepare input and output texts for training\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): List of input language sentences\n",
    "            output_texts (list): List of output language sentences\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tokenized and padded input and output sequences\n",
    "        \"\"\"\n",
    "        # Tokenize input texts\n",
    "        self.input_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.input_tokenizer.fit_on_texts(input_texts)\n",
    "        input_sequences = self.input_tokenizer.texts_to_sequences(input_texts)\n",
    "        encoder_input_data = pad_sequences(input_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Tokenize output texts\n",
    "        self.output_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.output_tokenizer.fit_on_texts(output_texts)\n",
    "        output_sequences = self.output_tokenizer.texts_to_sequences(output_texts)\n",
    "        decoder_input_data = pad_sequences(output_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # One-hot encode output sequences\n",
    "        # Shift the target data by one time step\n",
    "        decoder_target_data = np.zeros((len(output_texts), self.max_sequence_length,\n",
    "                                        len(self.output_tokenizer.word_index) + 1), dtype='float32')\n",
    "\n",
    "        for i, sequence in enumerate(decoder_input_data):\n",
    "            for t, word_index in enumerate(sequence):\n",
    "                if word_index > 0 and t > 0:\n",
    "                    decoder_target_data[i, t-1, word_index] = 1.0\n",
    "\n",
    "        # Get vocabulary sizes\n",
    "        input_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
    "        output_vocab_size = len(self.output_tokenizer.word_index) + 1\n",
    "\n",
    "        return (encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "                input_vocab_size, output_vocab_size)\n",
    "\n",
    "    def build_model(self, input_vocab_size, output_vocab_size):\n",
    "        \"\"\"\n",
    "        Build the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_vocab_size (int): Size of input language vocabulary\n",
    "            output_vocab_size (int): Size of output language vocabulary\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        encoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        encoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
    "        encoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        # Decoder\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        decoder_embedding = tf.keras.layers.Embedding(\n",
    "            output_vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
    "        decoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(\n",
    "            decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "        # Dense output layer\n",
    "        decoder_dense = tf.keras.layers.Dense(\n",
    "            output_vocab_size, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        # Compile the model\n",
    "        model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, input_texts, output_texts, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): Training input language sentences\n",
    "            output_texts (list): Training output language sentences\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "        \"\"\"\n",
    "        # Prepare data\n",
    "        (encoder_input_data, decoder_input_data,\n",
    "         decoder_target_data, input_vocab_size,\n",
    "         output_vocab_size) = self.prepare_data(input_texts, output_texts)\n",
    "\n",
    "        # Build model\n",
    "        self.build_model(input_vocab_size, output_vocab_size)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            [encoder_input_data, decoder_input_data],\n",
    "            decoder_target_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the entire model to a specified filepath\n",
    "        \"\"\"\n",
    "        self.model.save(filepath, save_format='h5')\n",
    "\n",
    "    def translate(self, input_sentence):\n",
    "        \"\"\"\n",
    "        Translate a single sentence\n",
    "\n",
    "        Args:\n",
    "            input_sentence (str): Sentence to translate\n",
    "\n",
    "        Returns:\n",
    "            str: Translated sentence\n",
    "        \"\"\"\n",
    "        if not self.model or not self.input_tokenizer or not self.output_tokenizer:\n",
    "            raise ValueError(\"Model must be trained before translation\")\n",
    "\n",
    "        # Tokenize and pad input sentence\n",
    "        input_seq = self.input_tokenizer.texts_to_sequences([input_sentence])\n",
    "        input_padded = pad_sequences(input_seq, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Prepare decoder input\n",
    "        decoder_input = np.zeros((1, self.max_sequence_length))\n",
    "        decoder_input[0, 0] = self.output_tokenizer.word_index.get('<start>', 1)  # Start token\n",
    "\n",
    "        # Translation process\n",
    "        translated_words = []\n",
    "        for i in range(self.max_sequence_length):\n",
    "            # Predict next word\n",
    "            output = self.model.predict([input_padded, decoder_input])\n",
    "\n",
    "            # Get the index of the word with the highest probability\n",
    "            predicted_word_index = np.argmax(output[0, i, :])\n",
    "\n",
    "            # Convert index to word\n",
    "            predicted_word = self.output_tokenizer.index_word.get(predicted_word_index, '')\n",
    "\n",
    "            # Stop if no word is predicted or we've reached max length\n",
    "            if not predicted_word or predicted_word == '<end>':\n",
    "                break\n",
    "\n",
    "            translated_words.append(predicted_word)\n",
    "\n",
    "            # Update decoder input\n",
    "            decoder_input[0, i+1] = predicted_word_index\n",
    "\n",
    "        return ' '.join(translated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7-MPdq-lciVx"
   },
   "outputs": [],
   "source": [
    "def read_texts_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            # Strip whitespace and remove empty lines\n",
    "            texts = ['<start> ' + line.strip() + ' <end>' for line in file if line.strip()]\n",
    "        return texts\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBuc1xSXciVx",
    "outputId": "7d2e447d-316c-4ed4-dd86-31b6f42ca8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.1991 - loss: 5.7619 - val_accuracy: 0.2236 - val_loss: 4.6257\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.2267 - loss: 4.4416 - val_accuracy: 0.2223 - val_loss: 4.5175\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.2261 - loss: 4.3356 - val_accuracy: 0.2327 - val_loss: 4.4433\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.2325 - loss: 4.2561 - val_accuracy: 0.2290 - val_loss: 4.3891\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.2402 - loss: 4.1511 - val_accuracy: 0.2411 - val_loss: 4.3198\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.2455 - loss: 4.0661 - val_accuracy: 0.2459 - val_loss: 4.2657\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.2504 - loss: 3.9721 - val_accuracy: 0.2467 - val_loss: 4.2360\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.2597 - loss: 3.8752 - val_accuracy: 0.2571 - val_loss: 4.1870\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.2683 - loss: 3.7646 - val_accuracy: 0.2622 - val_loss: 4.1302\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.2812 - loss: 3.6920 - val_accuracy: 0.2640 - val_loss: 4.1080\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.2884 - loss: 3.6173 - val_accuracy: 0.2654 - val_loss: 4.0959\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3003 - loss: 3.4950 - val_accuracy: 0.2699 - val_loss: 4.0396\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.3067 - loss: 3.4288 - val_accuracy: 0.2730 - val_loss: 4.0438\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.3175 - loss: 3.3465 - val_accuracy: 0.2718 - val_loss: 4.0174\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.3243 - loss: 3.2674 - val_accuracy: 0.2776 - val_loss: 3.9853\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.3299 - loss: 3.2022 - val_accuracy: 0.2785 - val_loss: 3.9834\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.3434 - loss: 3.1073 - val_accuracy: 0.2814 - val_loss: 3.9832\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3480 - loss: 3.0564 - val_accuracy: 0.2824 - val_loss: 3.9832\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3554 - loss: 2.9849 - val_accuracy: 0.2832 - val_loss: 3.9707\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.3668 - loss: 2.9059 - val_accuracy: 0.2848 - val_loss: 3.9681\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3781 - loss: 2.8119 - val_accuracy: 0.2872 - val_loss: 3.9761\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.3830 - loss: 2.7755 - val_accuracy: 0.2849 - val_loss: 3.9669\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3850 - loss: 2.7303 - val_accuracy: 0.2889 - val_loss: 3.9475\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.3941 - loss: 2.6773 - val_accuracy: 0.2895 - val_loss: 3.9677\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.4006 - loss: 2.5978 - val_accuracy: 0.2914 - val_loss: 3.9507\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.4117 - loss: 2.5407 - val_accuracy: 0.2908 - val_loss: 3.9701\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.4187 - loss: 2.4807 - val_accuracy: 0.2902 - val_loss: 3.9712\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.4239 - loss: 2.4351 - val_accuracy: 0.2923 - val_loss: 3.9786\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.4297 - loss: 2.3856 - val_accuracy: 0.2925 - val_loss: 3.9677\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.4333 - loss: 2.3506 - val_accuracy: 0.2921 - val_loss: 3.9780\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.4440 - loss: 2.2857 - val_accuracy: 0.2966 - val_loss: 3.9738\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.4480 - loss: 2.2373 - val_accuracy: 0.2979 - val_loss: 3.9840\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.4559 - loss: 2.1971 - val_accuracy: 0.2944 - val_loss: 3.9758\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.4600 - loss: 2.1457 - val_accuracy: 0.2989 - val_loss: 4.0109\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.4685 - loss: 2.0924 - val_accuracy: 0.2963 - val_loss: 3.9846\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.4763 - loss: 2.0425 - val_accuracy: 0.2979 - val_loss: 4.0022\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.4803 - loss: 2.0138 - val_accuracy: 0.2994 - val_loss: 4.0495\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.4838 - loss: 1.9742 - val_accuracy: 0.2995 - val_loss: 4.0191\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.4926 - loss: 1.9119 - val_accuracy: 0.3005 - val_loss: 4.0164\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.5020 - loss: 1.8730 - val_accuracy: 0.2996 - val_loss: 4.0260\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.5097 - loss: 1.8067 - val_accuracy: 0.3018 - val_loss: 4.0260\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5114 - loss: 1.7980 - val_accuracy: 0.3016 - val_loss: 4.0274\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.5202 - loss: 1.7482 - val_accuracy: 0.2984 - val_loss: 4.0610\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5206 - loss: 1.7249 - val_accuracy: 0.2996 - val_loss: 4.0415\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.5282 - loss: 1.6738 - val_accuracy: 0.3039 - val_loss: 4.0655\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.5364 - loss: 1.6211 - val_accuracy: 0.3025 - val_loss: 4.0734\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5413 - loss: 1.5860 - val_accuracy: 0.3047 - val_loss: 4.0784\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.5471 - loss: 1.5715 - val_accuracy: 0.3053 - val_loss: 4.0819\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.5507 - loss: 1.5278 - val_accuracy: 0.3023 - val_loss: 4.0975\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.5600 - loss: 1.4851 - val_accuracy: 0.3019 - val_loss: 4.1076\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5627 - loss: 1.4661 - val_accuracy: 0.3052 - val_loss: 4.1042\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.5685 - loss: 1.4127 - val_accuracy: 0.3050 - val_loss: 4.1133\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5757 - loss: 1.3747 - val_accuracy: 0.3037 - val_loss: 4.1414\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5820 - loss: 1.3579 - val_accuracy: 0.3035 - val_loss: 4.1383\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.5871 - loss: 1.3239 - val_accuracy: 0.3057 - val_loss: 4.1499\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5913 - loss: 1.2912 - val_accuracy: 0.3045 - val_loss: 4.1591\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5947 - loss: 1.2807 - val_accuracy: 0.3045 - val_loss: 4.1446\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6028 - loss: 1.2338 - val_accuracy: 0.3044 - val_loss: 4.1813\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.6093 - loss: 1.2088 - val_accuracy: 0.3067 - val_loss: 4.2032\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6160 - loss: 1.1610 - val_accuracy: 0.3063 - val_loss: 4.1941\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6208 - loss: 1.1416 - val_accuracy: 0.3065 - val_loss: 4.1868\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6232 - loss: 1.1168 - val_accuracy: 0.3054 - val_loss: 4.2128\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.6329 - loss: 1.0767 - val_accuracy: 0.3066 - val_loss: 4.2140\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.6353 - loss: 1.0663 - val_accuracy: 0.3084 - val_loss: 4.2164\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6429 - loss: 1.0411 - val_accuracy: 0.3049 - val_loss: 4.2516\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.6475 - loss: 1.0195 - val_accuracy: 0.3062 - val_loss: 4.2668\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.6526 - loss: 0.9896 - val_accuracy: 0.3067 - val_loss: 4.2571\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6557 - loss: 0.9723 - val_accuracy: 0.3078 - val_loss: 4.2785\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.6588 - loss: 0.9547 - val_accuracy: 0.3047 - val_loss: 4.2691\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.6652 - loss: 0.9242 - val_accuracy: 0.3063 - val_loss: 4.2859\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6708 - loss: 0.9037 - val_accuracy: 0.3067 - val_loss: 4.3030\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6745 - loss: 0.8733 - val_accuracy: 0.3053 - val_loss: 4.2928\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6790 - loss: 0.8448 - val_accuracy: 0.3083 - val_loss: 4.3031\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.6824 - loss: 0.8232 - val_accuracy: 0.3074 - val_loss: 4.3071\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6887 - loss: 0.8180 - val_accuracy: 0.3080 - val_loss: 4.3218\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.6944 - loss: 0.7879 - val_accuracy: 0.3064 - val_loss: 4.3496\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.6972 - loss: 0.7644 - val_accuracy: 0.3096 - val_loss: 4.3300\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7027 - loss: 0.7431 - val_accuracy: 0.3059 - val_loss: 4.3610\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.7045 - loss: 0.7343 - val_accuracy: 0.3083 - val_loss: 4.3627\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7104 - loss: 0.7019 - val_accuracy: 0.3083 - val_loss: 4.3552\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7113 - loss: 0.6876 - val_accuracy: 0.3103 - val_loss: 4.3829\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7158 - loss: 0.6552 - val_accuracy: 0.3077 - val_loss: 4.3800\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7176 - loss: 0.6559 - val_accuracy: 0.3096 - val_loss: 4.3907\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7197 - loss: 0.6368 - val_accuracy: 0.3075 - val_loss: 4.4016\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.7272 - loss: 0.6186 - val_accuracy: 0.3092 - val_loss: 4.4375\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7249 - loss: 0.6082 - val_accuracy: 0.3089 - val_loss: 4.4284\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7302 - loss: 0.5857 - val_accuracy: 0.3076 - val_loss: 4.4475\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7349 - loss: 0.5631 - val_accuracy: 0.3118 - val_loss: 4.4339\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7359 - loss: 0.5526 - val_accuracy: 0.3094 - val_loss: 4.4643\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7367 - loss: 0.5351 - val_accuracy: 0.3090 - val_loss: 4.4689\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7389 - loss: 0.5241 - val_accuracy: 0.3095 - val_loss: 4.4712\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7427 - loss: 0.5087 - val_accuracy: 0.3084 - val_loss: 4.4751\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7440 - loss: 0.4955 - val_accuracy: 0.3069 - val_loss: 4.4891\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7441 - loss: 0.4866 - val_accuracy: 0.3094 - val_loss: 4.4937\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7460 - loss: 0.4707 - val_accuracy: 0.3067 - val_loss: 4.5237\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7494 - loss: 0.4549 - val_accuracy: 0.3079 - val_loss: 4.5380\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7518 - loss: 0.4429 - val_accuracy: 0.3092 - val_loss: 4.5300\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7536 - loss: 0.4300 - val_accuracy: 0.3099 - val_loss: 4.5477\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.7548 - loss: 0.4196 - val_accuracy: 0.3055 - val_loss: 4.5585\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7555 - loss: 0.4124 - val_accuracy: 0.3082 - val_loss: 4.5554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Input: Let's try something.\n",
      "Translation: Quería entrar.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    model_save_path = 'en_sp_model.h5'\n",
    "\n",
    "\n",
    "    input_texts = read_texts_from_file('datasets/eng_sp.en')\n",
    "    output_texts = read_texts_from_file('datasets/spanish')\n",
    "\n",
    "    input_texts = input_texts[:10000]\n",
    "    output_texts = output_texts[:10000]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    nmt_model = NeuralMachineTranslation(max_sequence_length=5)\n",
    "\n",
    "    # Train the model\n",
    "    nmt_model.train(input_texts, output_texts, epochs=100)\n",
    "    nmt_model.save(model_save_path)\n",
    "\n",
    "    with open(\"en_sp_input_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.input_tokenizer, f)\n",
    "\n",
    "    with open(\"en_sp_output_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.output_tokenizer, f)\n",
    "\n",
    "\n",
    "\n",
    "    # Translate the first sentence\n",
    "    if input_texts:\n",
    "        input_sentence = input_texts[0].replace('<start>', '').replace('<end>', '').strip()\n",
    "        translation = nmt_model.translate(input_sentence)\n",
    "        print(f\"Input: {input_sentence}\")\n",
    "        print(f\"Translation: {translation}\")\n",
    "    else:\n",
    "        print(\"No input texts available for translation.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
