{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDZdOAjd7oIh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xuVLr3vb7oIk"
   },
   "outputs": [],
   "source": [
    "class NeuralMachineTranslation:\n",
    "    def __init__(self, max_sequence_length=10):\n",
    "        \"\"\"\n",
    "        Initialize Neural Machine Translation Model\n",
    "\n",
    "        Args:\n",
    "            max_sequence_length (int): Maximum length of input/output sequences\n",
    "        \"\"\"\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.input_tokenizer = None\n",
    "        self.output_tokenizer = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, input_texts, output_texts):\n",
    "        \"\"\"\n",
    "        Prepare input and output texts for training\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): List of input language sentences\n",
    "            output_texts (list): List of output language sentences\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tokenized and padded input and output sequences\n",
    "        \"\"\"\n",
    "        # Tokenize input texts\n",
    "        self.input_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.input_tokenizer.fit_on_texts(input_texts)\n",
    "        input_sequences = self.input_tokenizer.texts_to_sequences(input_texts)\n",
    "        encoder_input_data = pad_sequences(input_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Tokenize output texts\n",
    "        self.output_tokenizer = Tokenizer(filters='', lower=False)\n",
    "        self.output_tokenizer.fit_on_texts(output_texts)\n",
    "        output_sequences = self.output_tokenizer.texts_to_sequences(output_texts)\n",
    "        decoder_input_data = pad_sequences(output_sequences, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # One-hot encode output sequences\n",
    "        # Shift the target data by one time step\n",
    "        decoder_target_data = np.zeros((len(output_texts), self.max_sequence_length,\n",
    "                                        len(self.output_tokenizer.word_index) + 1), dtype='float32')\n",
    "\n",
    "        for i, sequence in enumerate(decoder_input_data):\n",
    "            for t, word_index in enumerate(sequence):\n",
    "                if word_index > 0 and t > 0:\n",
    "                    decoder_target_data[i, t-1, word_index] = 1.0\n",
    "\n",
    "        # Get vocabulary sizes\n",
    "        input_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
    "        output_vocab_size = len(self.output_tokenizer.word_index) + 1\n",
    "\n",
    "        return (encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "                input_vocab_size, output_vocab_size)\n",
    "\n",
    "    def build_model(self, input_vocab_size, output_vocab_size):\n",
    "        \"\"\"\n",
    "        Build the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_vocab_size (int): Size of input language vocabulary\n",
    "            output_vocab_size (int): Size of output language vocabulary\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        encoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        encoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
    "        encoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        # Decoder\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=(self.max_sequence_length,))\n",
    "        decoder_embedding = tf.keras.layers.Embedding(\n",
    "            output_vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
    "        decoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(\n",
    "            decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "        # Dense output layer\n",
    "        decoder_dense = tf.keras.layers.Dense(\n",
    "            output_vocab_size, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        # Compile the model\n",
    "        model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, input_texts, output_texts, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the Neural Machine Translation model\n",
    "\n",
    "        Args:\n",
    "            input_texts (list): Training input language sentences\n",
    "            output_texts (list): Training output language sentences\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "        \"\"\"\n",
    "        # Prepare data\n",
    "        (encoder_input_data, decoder_input_data,\n",
    "         decoder_target_data, input_vocab_size,\n",
    "         output_vocab_size) = self.prepare_data(input_texts, output_texts)\n",
    "\n",
    "        # Build model\n",
    "        self.build_model(input_vocab_size, output_vocab_size)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            [encoder_input_data, decoder_input_data],\n",
    "            decoder_target_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the entire model to a specified filepath\n",
    "        \"\"\"\n",
    "        self.model.save(filepath, save_format='h5')\n",
    "\n",
    "    def translate(self, input_sentence):\n",
    "        \"\"\"\n",
    "        Translate a single sentence\n",
    "\n",
    "        Args:\n",
    "            input_sentence (str): Sentence to translate\n",
    "\n",
    "        Returns:\n",
    "            str: Translated sentence\n",
    "        \"\"\"\n",
    "        if not self.model or not self.input_tokenizer or not self.output_tokenizer:\n",
    "            raise ValueError(\"Model must be trained before translation\")\n",
    "\n",
    "        # Tokenize and pad input sentence\n",
    "        input_seq = self.input_tokenizer.texts_to_sequences([input_sentence])\n",
    "        input_padded = pad_sequences(input_seq, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        # Prepare decoder input\n",
    "        decoder_input = np.zeros((1, self.max_sequence_length))\n",
    "        decoder_input[0, 0] = self.output_tokenizer.word_index.get('<start>', 1)  # Start token\n",
    "\n",
    "        # Translation process\n",
    "        translated_words = []\n",
    "        for i in range(self.max_sequence_length):\n",
    "            # Predict next word\n",
    "            output = self.model.predict([input_padded, decoder_input])\n",
    "\n",
    "            # Get the index of the word with the highest probability\n",
    "            predicted_word_index = np.argmax(output[0, i, :])\n",
    "\n",
    "            # Convert index to word\n",
    "            predicted_word = self.output_tokenizer.index_word.get(predicted_word_index, '')\n",
    "\n",
    "            # Stop if no word is predicted or we've reached max length\n",
    "            if not predicted_word or predicted_word == '<end>':\n",
    "                break\n",
    "\n",
    "            translated_words.append(predicted_word)\n",
    "\n",
    "            # Update decoder input\n",
    "            decoder_input[0, i+1] = predicted_word_index\n",
    "\n",
    "        return ' '.join(translated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "or5SNGoF7oIm"
   },
   "outputs": [],
   "source": [
    "def read_texts_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            # Strip whitespace and remove empty lines\n",
    "            texts = ['<start> ' + line.strip() + ' <end>' for line in file if line.strip()]\n",
    "        return texts\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvB0VZkQ7oIm",
    "outputId": "27f353d9-d8ce-4cb1-92a1-f1af20b117c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.2020 - loss: 5.1017 - val_accuracy: 0.2609 - val_loss: 3.8748\n",
      "Epoch 2/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.2640 - loss: 3.8356 - val_accuracy: 0.2630 - val_loss: 3.7644\n",
      "Epoch 3/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.2647 - loss: 3.7078 - val_accuracy: 0.2639 - val_loss: 3.6775\n",
      "Epoch 4/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.2662 - loss: 3.6078 - val_accuracy: 0.2695 - val_loss: 3.6016\n",
      "Epoch 5/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.2708 - loss: 3.5206 - val_accuracy: 0.2726 - val_loss: 3.5466\n",
      "Epoch 6/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.2753 - loss: 3.4416 - val_accuracy: 0.2731 - val_loss: 3.4891\n",
      "Epoch 7/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.2832 - loss: 3.3459 - val_accuracy: 0.2841 - val_loss: 3.4564\n",
      "Epoch 8/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.2882 - loss: 3.2573 - val_accuracy: 0.2955 - val_loss: 3.3863\n",
      "Epoch 9/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.3045 - loss: 3.1506 - val_accuracy: 0.2970 - val_loss: 3.3426\n",
      "Epoch 10/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3148 - loss: 3.0553 - val_accuracy: 0.3047 - val_loss: 3.3058\n",
      "Epoch 11/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.3291 - loss: 2.9554 - val_accuracy: 0.3101 - val_loss: 3.2925\n",
      "Epoch 12/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.3380 - loss: 2.8684 - val_accuracy: 0.3086 - val_loss: 3.2875\n",
      "Epoch 13/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.3479 - loss: 2.7690 - val_accuracy: 0.3119 - val_loss: 3.2202\n",
      "Epoch 14/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.3569 - loss: 2.6962 - val_accuracy: 0.3205 - val_loss: 3.2010\n",
      "Epoch 15/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.3701 - loss: 2.5917 - val_accuracy: 0.3160 - val_loss: 3.1893\n",
      "Epoch 16/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.3767 - loss: 2.5377 - val_accuracy: 0.3235 - val_loss: 3.1601\n",
      "Epoch 17/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.3858 - loss: 2.4673 - val_accuracy: 0.3301 - val_loss: 3.1517\n",
      "Epoch 18/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.3952 - loss: 2.4080 - val_accuracy: 0.3318 - val_loss: 3.1301\n",
      "Epoch 19/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.4032 - loss: 2.3194 - val_accuracy: 0.3326 - val_loss: 3.1437\n",
      "Epoch 20/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4082 - loss: 2.2661 - val_accuracy: 0.3352 - val_loss: 3.1316\n",
      "Epoch 21/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.4191 - loss: 2.1951 - val_accuracy: 0.3314 - val_loss: 3.1418\n",
      "Epoch 22/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.4258 - loss: 2.1423 - val_accuracy: 0.3368 - val_loss: 3.1378\n",
      "Epoch 23/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.4335 - loss: 2.0797 - val_accuracy: 0.3402 - val_loss: 3.1115\n",
      "Epoch 24/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.4445 - loss: 1.9944 - val_accuracy: 0.3425 - val_loss: 3.1091\n",
      "Epoch 25/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.4550 - loss: 1.9516 - val_accuracy: 0.3389 - val_loss: 3.1137\n",
      "Epoch 26/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.4638 - loss: 1.8869 - val_accuracy: 0.3432 - val_loss: 3.0829\n",
      "Epoch 27/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4764 - loss: 1.7907 - val_accuracy: 0.3445 - val_loss: 3.1034\n",
      "Epoch 28/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4839 - loss: 1.7609 - val_accuracy: 0.3462 - val_loss: 3.1253\n",
      "Epoch 29/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.4869 - loss: 1.7170 - val_accuracy: 0.3449 - val_loss: 3.1247\n",
      "Epoch 30/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.4973 - loss: 1.6570 - val_accuracy: 0.3466 - val_loss: 3.1384\n",
      "Epoch 31/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5096 - loss: 1.5897 - val_accuracy: 0.3449 - val_loss: 3.1561\n",
      "Epoch 32/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.5152 - loss: 1.5474 - val_accuracy: 0.3482 - val_loss: 3.1676\n",
      "Epoch 33/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5217 - loss: 1.5158 - val_accuracy: 0.3477 - val_loss: 3.1583\n",
      "Epoch 34/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.5322 - loss: 1.4488 - val_accuracy: 0.3495 - val_loss: 3.1778\n",
      "Epoch 35/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5424 - loss: 1.3825 - val_accuracy: 0.3496 - val_loss: 3.1774\n",
      "Epoch 36/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5488 - loss: 1.3564 - val_accuracy: 0.3499 - val_loss: 3.2013\n",
      "Epoch 37/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5567 - loss: 1.2953 - val_accuracy: 0.3493 - val_loss: 3.2328\n",
      "Epoch 38/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.5700 - loss: 1.2274 - val_accuracy: 0.3504 - val_loss: 3.2560\n",
      "Epoch 39/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5738 - loss: 1.2057 - val_accuracy: 0.3484 - val_loss: 3.2390\n",
      "Epoch 40/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5793 - loss: 1.1708 - val_accuracy: 0.3479 - val_loss: 3.2525\n",
      "Epoch 41/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5875 - loss: 1.1228 - val_accuracy: 0.3513 - val_loss: 3.2714\n",
      "Epoch 42/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5991 - loss: 1.0668 - val_accuracy: 0.3521 - val_loss: 3.2902\n",
      "Epoch 43/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6042 - loss: 1.0382 - val_accuracy: 0.3532 - val_loss: 3.2903\n",
      "Epoch 44/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6078 - loss: 1.0069 - val_accuracy: 0.3522 - val_loss: 3.3255\n",
      "Epoch 45/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6152 - loss: 0.9673 - val_accuracy: 0.3501 - val_loss: 3.3606\n",
      "Epoch 46/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6183 - loss: 0.9418 - val_accuracy: 0.3517 - val_loss: 3.3585\n",
      "Epoch 47/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6311 - loss: 0.8988 - val_accuracy: 0.3498 - val_loss: 3.4043\n",
      "Epoch 48/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6372 - loss: 0.8631 - val_accuracy: 0.3549 - val_loss: 3.3495\n",
      "Epoch 49/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6431 - loss: 0.8199 - val_accuracy: 0.3527 - val_loss: 3.3799\n",
      "Epoch 50/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6461 - loss: 0.7996 - val_accuracy: 0.3542 - val_loss: 3.4210\n",
      "Epoch 51/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6523 - loss: 0.7831 - val_accuracy: 0.3518 - val_loss: 3.4055\n",
      "Epoch 52/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6600 - loss: 0.7365 - val_accuracy: 0.3525 - val_loss: 3.4251\n",
      "Epoch 53/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.6650 - loss: 0.7180 - val_accuracy: 0.3538 - val_loss: 3.4389\n",
      "Epoch 54/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6706 - loss: 0.7003 - val_accuracy: 0.3546 - val_loss: 3.4432\n",
      "Epoch 55/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6775 - loss: 0.6558 - val_accuracy: 0.3550 - val_loss: 3.4765\n",
      "Epoch 56/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.6804 - loss: 0.6426 - val_accuracy: 0.3533 - val_loss: 3.4861\n",
      "Epoch 57/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6861 - loss: 0.6141 - val_accuracy: 0.3506 - val_loss: 3.5606\n",
      "Epoch 58/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6943 - loss: 0.5982 - val_accuracy: 0.3585 - val_loss: 3.5112\n",
      "Epoch 59/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6980 - loss: 0.5747 - val_accuracy: 0.3547 - val_loss: 3.5310\n",
      "Epoch 60/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7016 - loss: 0.5491 - val_accuracy: 0.3526 - val_loss: 3.5522\n",
      "Epoch 61/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.7057 - loss: 0.5326 - val_accuracy: 0.3548 - val_loss: 3.5951\n",
      "Epoch 62/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7116 - loss: 0.5041 - val_accuracy: 0.3517 - val_loss: 3.5763\n",
      "Epoch 63/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7126 - loss: 0.4798 - val_accuracy: 0.3534 - val_loss: 3.6108\n",
      "Epoch 64/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7154 - loss: 0.4736 - val_accuracy: 0.3537 - val_loss: 3.6089\n",
      "Epoch 65/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7161 - loss: 0.4607 - val_accuracy: 0.3553 - val_loss: 3.6314\n",
      "Epoch 66/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7203 - loss: 0.4302 - val_accuracy: 0.3548 - val_loss: 3.6427\n",
      "Epoch 67/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7233 - loss: 0.4197 - val_accuracy: 0.3540 - val_loss: 3.6518\n",
      "Epoch 68/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7261 - loss: 0.4059 - val_accuracy: 0.3549 - val_loss: 3.6667\n",
      "Epoch 69/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7260 - loss: 0.3903 - val_accuracy: 0.3554 - val_loss: 3.6874\n",
      "Epoch 70/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7306 - loss: 0.3768 - val_accuracy: 0.3530 - val_loss: 3.7095\n",
      "Epoch 71/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7293 - loss: 0.3688 - val_accuracy: 0.3523 - val_loss: 3.7398\n",
      "Epoch 72/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7292 - loss: 0.3503 - val_accuracy: 0.3559 - val_loss: 3.7584\n",
      "Epoch 73/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7321 - loss: 0.3373 - val_accuracy: 0.3576 - val_loss: 3.7269\n",
      "Epoch 74/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7328 - loss: 0.3282 - val_accuracy: 0.3546 - val_loss: 3.7725\n",
      "Epoch 75/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7340 - loss: 0.3158 - val_accuracy: 0.3549 - val_loss: 3.7609\n",
      "Epoch 76/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7351 - loss: 0.3008 - val_accuracy: 0.3578 - val_loss: 3.7892\n",
      "Epoch 77/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7369 - loss: 0.2865 - val_accuracy: 0.3553 - val_loss: 3.8066\n",
      "Epoch 78/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.7367 - loss: 0.2844 - val_accuracy: 0.3535 - val_loss: 3.8222\n",
      "Epoch 79/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7401 - loss: 0.2700 - val_accuracy: 0.3544 - val_loss: 3.8444\n",
      "Epoch 80/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7395 - loss: 0.2656 - val_accuracy: 0.3529 - val_loss: 3.8679\n",
      "Epoch 81/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7412 - loss: 0.2603 - val_accuracy: 0.3531 - val_loss: 3.8724\n",
      "Epoch 82/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7387 - loss: 0.2497 - val_accuracy: 0.3553 - val_loss: 3.8969\n",
      "Epoch 83/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.7406 - loss: 0.2457 - val_accuracy: 0.3496 - val_loss: 3.9366\n",
      "Epoch 84/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.7431 - loss: 0.2361 - val_accuracy: 0.3543 - val_loss: 3.9180\n",
      "Epoch 85/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7416 - loss: 0.2309 - val_accuracy: 0.3531 - val_loss: 3.9256\n",
      "Epoch 86/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7434 - loss: 0.2214 - val_accuracy: 0.3518 - val_loss: 3.9407\n",
      "Epoch 87/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7440 - loss: 0.2211 - val_accuracy: 0.3527 - val_loss: 3.9783\n",
      "Epoch 88/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7468 - loss: 0.2066 - val_accuracy: 0.3552 - val_loss: 3.9521\n",
      "Epoch 89/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7471 - loss: 0.2041 - val_accuracy: 0.3498 - val_loss: 3.9953\n",
      "Epoch 90/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7443 - loss: 0.1981 - val_accuracy: 0.3492 - val_loss: 4.0065\n",
      "Epoch 91/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7470 - loss: 0.1947 - val_accuracy: 0.3502 - val_loss: 4.0201\n",
      "Epoch 92/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.7463 - loss: 0.1885 - val_accuracy: 0.3531 - val_loss: 4.0273\n",
      "Epoch 93/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7487 - loss: 0.1821 - val_accuracy: 0.3511 - val_loss: 4.0542\n",
      "Epoch 94/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7454 - loss: 0.1831 - val_accuracy: 0.3513 - val_loss: 4.0661\n",
      "Epoch 95/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7461 - loss: 0.1823 - val_accuracy: 0.3538 - val_loss: 4.0728\n",
      "Epoch 96/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7461 - loss: 0.1739 - val_accuracy: 0.3483 - val_loss: 4.1027\n",
      "Epoch 97/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7480 - loss: 0.1697 - val_accuracy: 0.3518 - val_loss: 4.1017\n",
      "Epoch 98/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7497 - loss: 0.1638 - val_accuracy: 0.3461 - val_loss: 4.1508\n",
      "Epoch 99/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7487 - loss: 0.1627 - val_accuracy: 0.3503 - val_loss: 4.1380\n",
      "Epoch 100/100\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.1590 - val_accuracy: 0.3484 - val_loss: 4.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Input: I have to go to sleep.\n",
      "Translation: तुम्हें जाना होगा।\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    input_texts = read_texts_from_file('datasets/eng_hi')\n",
    "    output_texts = read_texts_from_file('datasets/hindi')\n",
    "\n",
    "    model_save_path = 'en_hi_model.h5'\n",
    "\n",
    "\n",
    "    # Initialize and train the model\n",
    "    nmt_model = NeuralMachineTranslation(max_sequence_length=5)\n",
    "\n",
    "    # Train the model\n",
    "    nmt_model.train(input_texts, output_texts, epochs=100)\n",
    "\n",
    "    nmt_model.save(model_save_path)\n",
    "\n",
    "    with open(\"en_hi_input_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.input_tokenizer, f)\n",
    "\n",
    "    with open(\"en_hi_output_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nmt_model.output_tokenizer, f)\n",
    "\n",
    "\n",
    "    # Translate the first sentence\n",
    "    if input_texts:\n",
    "        input_sentence = input_texts[0].replace('<start>', '').replace('<end>', '').strip()\n",
    "        translation = nmt_model.translate(input_sentence)\n",
    "        print(f\"Input: {input_sentence}\")\n",
    "        print(f\"Translation: {translation}\")\n",
    "    else:\n",
    "        print(\"No input texts available for translation.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
